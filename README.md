# computational_bias_detection
Master Thesis Project Code
The rapid increase of refugees around the world is one of the prominent global issues of the 21st century. It has gained widespread coverage in the news media, and significantly influenced the public's perception about refugees. The feasibility to explore news media is increasing with developments within natural language processing and computational analysis. 
To gain insights into this issue, this study proposes a framework for detecting bias in English written news media. This is executed through investigating a collection of news media articles covering Syrian refugees and Ukrainian refugees, respectively. A comparative computational analysis is conducted through exploring bias by word choice and labeling with the applied methods of frame identification, semantic similarities and aspect based sentiment analysis on full article content. The research question that this thesis strives to answer is;  How can bias in news media be detected through computational methods? The general frames identified for the full dataset were Displacement, Humanitarian, Political and Violence and serves as a contextual segmentation for the further analysis. The findings confirms an indication of bias favoring Ukrainian refugees above Syrian refugees based on the data and is most apparent within the Displacement frame. However, a detected underlying bias in the pre-trained language model for sentiment analysis explains part of this study’s identified bias. This motivates further research to use language models that have been fine-tuned on the specific subject data and remain critical to pre-trained language models. The study emphasizes the usefulness of the framework for primarily humanitarian help organizations to use as a tool in monitoring media bias. By doing so, this study seeks to contribute to the development of more objective, efficient, and scalable methods within the field of bias detection.

Results from Frame Identification
<img width="282" alt="Skärmavbild 2023-05-12 kl  11 09 16" src="https://github.com/visu21ab/computational_bias_detection/assets/91184444/8771356e-d703-4dac-9dfc-8e80e7715b0b">
